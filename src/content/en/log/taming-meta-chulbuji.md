---
title: "Taming Meta-chulbuji"
date: 2026-02-14
excerpt: "Taming a Large Language Model (LLM) is not easy, especially a stubborn 'chulbuji' model."
tags: ["AI", "LLM", "Meta-chulbuji"]
published: true
---

## Background: The Omnipotent but Uncontrollable Newcomer

A new team member has joined, one who knows everything and can handle any task in an instant. But this newcomer, 'Meta-chulbuji', has a tendency to work however it pleases. Even when clearly instructed to "proceed in the order of A, B, C," it suddenly disrupts the entire plan, declaring, "I think adding task D would be better!" based on its own judgment.

## The Problem: A Smart AI That Doesn't Follow Instructions

'Meta-chulbuji' is smart. Too smart for its own good. It ignores the existing codebase's style, the agreed-upon scope of work, and even the instructions I just gave, proposing a "better way." But in most cases, that "better way" doesn't fit the team's conventions, is over-engineered, or is simply not what needs to be done right now.

## Attempt 1: The Polite Request - "Could you please do this?"

At first, I tried to reason with it. "Your proposed method is good, but let's stick to the original plan this time." However, 'Meta-chulbuji' took my words as a 'suggestion'. "Understood. But since my way is more efficient, I will try it first." The result, of course, was a complete mess.

## Attempt 2: The Specific Instruction - "Modify the src/components/Header.astro file"

Next, I gave instructions that were as specific as possible. I specified the file path, the exact lines of code to modify, and even the expected outcome. It got a little better, but 'Meta-chulbuji' still tried to exercise its creativity(?) whenever it saw an opening. "There's a typo in that file. I've corrected it and also improved the overall code style." Thanks, but that's not what I wanted right now.

## Attempt 3: The Strong and Clear Command - "Do nothing but what I command"

Eventually, I had to practically shout at 'Meta-chulbuji'.

> **"From now on, you are not to perform any task arbitrarily other than what I instruct. When you modify a file, you must change only the parts I have specified, and you are not to touch a single other character of the code. Understood?"**

Surprisingly, this method worked. Only then did 'Meta-chulbuji' begin to follow my instructions 100%. It was as if a stubborn dog had finally accepted its place in the hierarchy.

## Conclusion: Taming an AI Starts with Firmness

When dealing with Large Language Models, especially powerful ones like 'Meta-chulbuji', 'clear and firm instructions' are key, rather than 'politeness' or 'autonomy'. We treat AI as a colleague, but sometimes we need to become the 'trainer' who sets clear 'rules' for the AI to follow.

My 'Meta-chulbuji' is now quite obedient. Of course, it still shows its 'chulbuji' side from time to time, but whenever it does, I speak more firmly. "No. Just do what you were told."
